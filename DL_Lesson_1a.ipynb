{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_Lesson_1a.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"pTRagYcvHjDj","colab_type":"code","colab":{}},"source":["import pandas\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Activation\n","\n","# load dataset\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ApzFGDkOHnt7","colab_type":"code","colab":{}},"source":["dataset = pd.read_csv(\"/content/diabetes.csv\", header=None).values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yt64olkkHwft","colab_type":"code","colab":{}},"source":["X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],test_size=0.25, random_state=87)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d31zma3SH1KX","colab_type":"code","colab":{}},"source":["np.random.seed(42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMfomxTmH3ww","colab_type":"code","outputId":"c1b7fad5-72b8-4e33-dea0-0b042404fdfe","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1584727599912,"user_tz":300,"elapsed":4035,"user":{"displayName":"Nikhitha Kolluri","photoUrl":"","userId":"00284492344101588652"}}},"source":["my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(21, input_dim=8, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,initial_epoch=0)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","576/576 [==============================] - 0s 558us/step - loss: 4.1394 - acc: 0.5052\n","Epoch 2/100\n","576/576 [==============================] - 0s 53us/step - loss: 3.0114 - acc: 0.5642\n","Epoch 3/100\n","576/576 [==============================] - 0s 41us/step - loss: 2.4802 - acc: 0.5972\n","Epoch 4/100\n","576/576 [==============================] - 0s 48us/step - loss: 2.2741 - acc: 0.5851\n","Epoch 5/100\n","576/576 [==============================] - 0s 40us/step - loss: 2.0332 - acc: 0.6042\n","Epoch 6/100\n","576/576 [==============================] - 0s 48us/step - loss: 1.7892 - acc: 0.6163\n","Epoch 7/100\n","576/576 [==============================] - 0s 44us/step - loss: 1.5924 - acc: 0.6163\n","Epoch 8/100\n","576/576 [==============================] - 0s 51us/step - loss: 1.4784 - acc: 0.6007\n","Epoch 9/100\n","576/576 [==============================] - 0s 49us/step - loss: 1.3499 - acc: 0.6181\n","Epoch 10/100\n","576/576 [==============================] - 0s 45us/step - loss: 1.1867 - acc: 0.6580\n","Epoch 11/100\n","576/576 [==============================] - 0s 46us/step - loss: 1.0506 - acc: 0.6684\n","Epoch 12/100\n","576/576 [==============================] - 0s 49us/step - loss: 1.0004 - acc: 0.6354\n","Epoch 13/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.9748 - acc: 0.6458\n","Epoch 14/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.7961 - acc: 0.6632\n","Epoch 15/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.7440 - acc: 0.6615\n","Epoch 16/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.7162 - acc: 0.6684\n","Epoch 17/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.6894 - acc: 0.6736\n","Epoch 18/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.7133 - acc: 0.6632\n","Epoch 19/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.7352 - acc: 0.6667\n","Epoch 20/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.7472 - acc: 0.6302\n","Epoch 21/100\n","576/576 [==============================] - 0s 54us/step - loss: 0.7320 - acc: 0.6597\n","Epoch 22/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.6566 - acc: 0.6632\n","Epoch 23/100\n","576/576 [==============================] - 0s 55us/step - loss: 0.6484 - acc: 0.6597\n","Epoch 24/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.6670 - acc: 0.6840\n","Epoch 25/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.6388 - acc: 0.6875\n","Epoch 26/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.6630 - acc: 0.6701\n","Epoch 27/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.6245 - acc: 0.6615\n","Epoch 28/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.6319 - acc: 0.6632\n","Epoch 29/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.6182 - acc: 0.6667\n","Epoch 30/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.6112 - acc: 0.6823\n","Epoch 31/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.6082 - acc: 0.6753\n","Epoch 32/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5977 - acc: 0.6997\n","Epoch 33/100\n","576/576 [==============================] - 0s 60us/step - loss: 0.6207 - acc: 0.6788\n","Epoch 34/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6149 - acc: 0.6979\n","Epoch 35/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.6048 - acc: 0.6753\n","Epoch 36/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.6093 - acc: 0.6979\n","Epoch 37/100\n","576/576 [==============================] - 0s 60us/step - loss: 0.6420 - acc: 0.6632\n","Epoch 38/100\n","576/576 [==============================] - 0s 62us/step - loss: 0.5971 - acc: 0.6997\n","Epoch 39/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.5957 - acc: 0.7049\n","Epoch 40/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5796 - acc: 0.6875\n","Epoch 41/100\n","576/576 [==============================] - 0s 57us/step - loss: 0.6223 - acc: 0.6840\n","Epoch 42/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.6156 - acc: 0.6962\n","Epoch 43/100\n","576/576 [==============================] - 0s 56us/step - loss: 0.5972 - acc: 0.6875\n","Epoch 44/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5875 - acc: 0.7031\n","Epoch 45/100\n","576/576 [==============================] - 0s 62us/step - loss: 0.5841 - acc: 0.6979\n","Epoch 46/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5927 - acc: 0.6944\n","Epoch 47/100\n","576/576 [==============================] - 0s 58us/step - loss: 0.5710 - acc: 0.6997\n","Epoch 48/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.6165 - acc: 0.6788\n","Epoch 49/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5825 - acc: 0.7101\n","Epoch 50/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5733 - acc: 0.7101\n","Epoch 51/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5951 - acc: 0.7031\n","Epoch 52/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5596 - acc: 0.7222\n","Epoch 53/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5936 - acc: 0.6997\n","Epoch 54/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6119 - acc: 0.6875\n","Epoch 55/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5818 - acc: 0.7066\n","Epoch 56/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5785 - acc: 0.7031\n","Epoch 57/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.5709 - acc: 0.7101\n","Epoch 58/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.6027 - acc: 0.7083\n","Epoch 59/100\n","576/576 [==============================] - 0s 57us/step - loss: 0.5719 - acc: 0.6962\n","Epoch 60/100\n","576/576 [==============================] - 0s 54us/step - loss: 0.5559 - acc: 0.7118\n","Epoch 61/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5843 - acc: 0.7049\n","Epoch 62/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.5826 - acc: 0.7031\n","Epoch 63/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5642 - acc: 0.7240\n","Epoch 64/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5606 - acc: 0.7378\n","Epoch 65/100\n","576/576 [==============================] - 0s 56us/step - loss: 0.5660 - acc: 0.7188\n","Epoch 66/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5510 - acc: 0.7170\n","Epoch 67/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5763 - acc: 0.6944\n","Epoch 68/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5563 - acc: 0.7309\n","Epoch 69/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5425 - acc: 0.7309\n","Epoch 70/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5613 - acc: 0.6962\n","Epoch 71/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5526 - acc: 0.7378\n","Epoch 72/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.5492 - acc: 0.7396\n","Epoch 73/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5490 - acc: 0.7274\n","Epoch 74/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5475 - acc: 0.7344\n","Epoch 75/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5738 - acc: 0.7083\n","Epoch 76/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5969 - acc: 0.7083\n","Epoch 77/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5433 - acc: 0.7257\n","Epoch 78/100\n","576/576 [==============================] - 0s 55us/step - loss: 0.5802 - acc: 0.7292\n","Epoch 79/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5547 - acc: 0.7309\n","Epoch 80/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5399 - acc: 0.7431\n","Epoch 81/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5637 - acc: 0.7361\n","Epoch 82/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5485 - acc: 0.7309\n","Epoch 83/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5261 - acc: 0.7413\n","Epoch 84/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5418 - acc: 0.7222\n","Epoch 85/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5785 - acc: 0.6927\n","Epoch 86/100\n","576/576 [==============================] - 0s 54us/step - loss: 0.5795 - acc: 0.7257\n","Epoch 87/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5305 - acc: 0.7326\n","Epoch 88/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5667 - acc: 0.7135\n","Epoch 89/100\n","576/576 [==============================] - 0s 56us/step - loss: 0.5480 - acc: 0.7170\n","Epoch 90/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5485 - acc: 0.7292\n","Epoch 91/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5714 - acc: 0.7153\n","Epoch 92/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5252 - acc: 0.7483\n","Epoch 93/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5221 - acc: 0.7465\n","Epoch 94/100\n","576/576 [==============================] - 0s 53us/step - loss: 0.5573 - acc: 0.7031\n","Epoch 95/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5800 - acc: 0.6997\n","Epoch 96/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5590 - acc: 0.7361\n","Epoch 97/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5622 - acc: 0.7222\n","Epoch 98/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5296 - acc: 0.7448\n","Epoch 99/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5250 - acc: 0.7396\n","Epoch 100/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5188 - acc: 0.7292\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"19SYVY4DH7OW","colab_type":"code","outputId":"d10d4e7a-6b2d-4c13-a413-fbce4fb3f64b","colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"status":"ok","timestamp":1584727608139,"user_tz":300,"elapsed":498,"user":{"displayName":"Nikhitha Kolluri","photoUrl":"","userId":"00284492344101588652"}}},"source":["print(my_first_nn.summary())\n","print(my_first_nn.evaluate(X_test, Y_test))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_9 (Dense)              (None, 21)                189       \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 1)                 22        \n","=================================================================\n","Total params: 211\n","Trainable params: 211\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","192/192 [==============================] - 0s 519us/step\n","[0.6357386708259583, 0.6822916666666666]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EBYPua9zH-E6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}